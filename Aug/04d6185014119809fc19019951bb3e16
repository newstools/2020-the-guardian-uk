In April 2020, Amazon, the world’s wealthiest technology company, received a shipment of 1,500 heat-mapping camera systems from the Chinese surveillance company Dahua. Many of these systems will be installed in Amazon warehouses to monitor the heat signatures of employees and alert managers if workers exhibit Covid-19-like symptoms. Other cameras included in the shipment will be distributed to IBM and Chrysler, among other buyers. While Amazon’s move to protect workers from Covid-19 is welcome, it acquired this technology from a company from a company researchers have shown is involved in human rights abuses. As Sanjana Varghese noted recently, the “humanitarian experimentation” work in pandemic surveillance of companies like Dahua doubles as technologies of population management. In north-west China, where Dahua is heavily invested, Dahua’s public health surveillance applications mask its involvement in a system of “terror capitalism” that has placed as many as 1.5 million Muslims in internment camps in the Uighur region in north-west China. Dahua received close to $1bn to build comprehensive surveillance enclosures which allegedly supported a “re-education” system of internment, checkpoints, and ideological training as part of a “people’s war on terror” in north-west China. Because of its role in human rights abuses, the US department of commerce has placed Dahua on a list that prohibits American companies from selling products to it. Like many computer-vision companies in China, Dahua got its start through partnerships with the ministry of state security, China’s version of the CIA. Like its rivals Hikvision, SenseTime, Yitu, and others, it now receives much of its funding from Chinese state security projects. These companies provide “smart city” tools to authorities that allow them to analyze and control populations in a manner that resembles the role of the US Department of Defense contractor Palantir, which provides analytics to police departments throughout the US. In north-west China, this means surveilling people using social media data, GPS tracking and face recognition checkpoints to make their behavior searchable. Companies like Dahua installed automated sensors and camera systems in markets, transportation hubs and mosques, including face recognition cameras to identify people by ethnicity. They also began advertising “smart camp” systems that used smart technologies and analytics to “control people and vehicles”. Setting aside Amazon’s own role in involuntary surveillance with its Rekognition software, the company’s purchase of Dahua heat-mapping cameras reminds me of an older moment in the spread of global capitalism, captured by the historian Jason Moore’s memorable turn of phrase: “Behind Manchester stands Mississippi.” What Moore meant by this, in his re-reading of Friedrich Engels’ analysis of the textile industry that made Manchester, England, so profitable, is that many aspects of the British industrial revolution would not have been possible without the cheap cotton produced by slave labor in the United States. In a similar way, the ability of Seattle-based tech companies like Amazon to respond to the pandemic relies in part on systems of oppression in north-west China which experiment with biometric surveillance technologies. There are reasons why a Chinese fleet of AI national champions, many of which have applications similar to American surveillance companies such as Clearview and Raytheon, now lead the world in face and voice recognition. This process was accelerated by the Chinese “war on terror” focused on encircling Uighurs and Kazakhs within a complex digital enclosure; it now extends throughout the Chinese technology industry, where data-intensive infrastructure systems produce flexible digital enclosures throughout the nation, though not at the same scale as in Xinjiang. China’s vast and rapid response to the pandemic has further accelerated this process by rapidly implementing these systems and making clear that they work. Because they extend state power in such sweeping and intimate ways they can effectively alter human behavior. But the Chinese approach to the pandemic is not the only way to stop it. Democratic states like New Zealand and Canada, which have provided testing, masks and economic assistance to those forced to stay home, have also been effective. These nations show us that surveillance is not necessary to protect wellbeing, even at the level of the nation. In fact, numerous studies have shown that surveillance systems support systemic racism. In the wake of nationwide protests against police brutality in the United States, companies like Amazon and IBM have announced temporary moratoriums on providing face recognition systems to US police departments. Many critics have noted that while this is a good first step in halting the spread of technologies that disproportionately harm minorities, it is not enough. The majority of companies invested in building invasive surveillance tools for American police have not agreed to stop. Algorithms make it appear normal that black men or Uighurs are disproportionately detected by these systems Despite the US moratorium on sales to Dahua and more than two dozen Chinese companies, companies like Amazon have not agreed to stop using systems from companies like Dahua. Perhaps they, like many in the tech community, recognize that the current US administration is using a double standard, by punishing Chinese firms for automating racialization and extralegal detention while funding American companies to do similar things, though at a smaller scale. Instead, in many ways race continues to be a little-considered part of how people interact with the world. Police in the US, and in China, think about automated assessment technologies as tools they can use to detect potential criminals or terrorists. The algorithms make it appear normal that black men or Uighurs are disproportionately detected by these systems. They stop the police, and those they protect, from recognizing that surveillance is always about controlling and disciplining people who do not fully conform to the vision of those in power. Halting the spread of automated racialization must be divorced from the Trump administration’s disastrous and often racialized China policy. Though the breadth and cruelty of the system in China is unprecedented, the world, not China alone, has a problem with surveillance. It demands a response that is likewise global in scale. While it is important that global companies like IBM, which coined the term “smart city”, are taking temporary stands against these technologies being used by US police, they must also stop collaborating with Chinese police contractors. To counteract the increasing banality, the everydayness, of automated racialization, the harms of biometric surveillance around the world must first be made apparent. Then the interconnections of these surveillance companies – the way Xinjiang stands behind Seattle – must be made thinkable. Only then can they be regulated from the perspective of the oppressed. Nations in Asia and around the globe must introduce a new legal instrument that would begin to build global protections for all humans, particularly minorities, from such surveillance technologies, on a country-neutral and company-neutral basis. To the extent that such a cyber court was empowered and effective it could begin to hold companies like Amazon and Dahua to the same global standards. Dr Darren Byler is an anthropologist at the University of Colorado and the author of two forthcoming books, one on the effects of terror capitalism among Uighurs and one on technologies of re-education in China and around the world
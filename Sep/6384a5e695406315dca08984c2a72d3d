The long-awaited Facebook Oversight Board, empowered to overrule some of the platform’s content moderation decisions, plans to launch in October, just in time for the US election. The board will be ready to hear appeals from Facebook users as well as cases referred by the company itself “as soon as mid- or late-October at the very latest, unless there are some major technical issues that come up”, said Julie Owono, one of the 20 initial members of the committee who were named in May, in an interview on Wednesday. “The board is paying attention, and is, of course, aware of the worries around this election and the role that social media will play,” said Owono, who is also the executive director of the digital rights organization Internet Sans Frontières. “When we launch, we will be ready to take requests, wherever they come from, and from whoever they come from, as long as it’s within our mandate.” The launch will come at a time of intense scrutiny and pressure for the company that has lurched from controversy to controversy since it was used by Russia to interfere with the 2016 US presidential election. The consequences of Facebook’s failures in addressing hate speech and incitement, which have for years been linked to violence in several countries and ethnic cleansing in Myanmar, have become increasingly apparent in its home country in recent months. During a summer of civil unrest in the US, Facebook was linked to the growth of the violent Boogaloo movement and a militia’s “call to arms” on the night two Black Lives Matter protesters were shot and killed in Kenosha, Wisconsin. The limits of the oversight board’s mandate have been a key point of controversy since the independent institution was proposed by Facebook’s chief executive, Mark Zuckerberg, in 2018. The board’s initial bylaws only allowed it to consider appeals from users who believe that individual pieces of content were unfairly removed, prompting criticism from experts, including Evelyn Douek, a lecturer at Harvard Law School who studies online speech regulation. “We were told this was going to be the supreme court of Facebook, but then it came out more like a local district court, and now it’s more of a traffic court,” Douek told the Guardian. “It’s just been steadily narrowed over time.” Crucial areas where Facebook exercises editorial control include the algorithms that shape what content receives the most distribution; decisions to take down or leave up Facebook groups, pages and events; and decisions to leave certain pieces of content up. The board would be considering “leave up” decisions as soon as it launched, Owono said, but only if Facebook referred a case to it. She said technical and privacy challenges had delayed the launch of a system for Facebook users to appeal “leave up” decisions, but that one would be available “as soon as possible”. Facebook’s decisions to leave certain content up, such as its decision not to remove a post by Donald Trump threatening Black Lives Matter protesters that “when the looting starts the shooting starts”, have become as controversial, if not more so, than its decisions to take certain content down. Owono said “checks and balances are needed everywhere”, including across the aspects of Facebook not included in the oversight board’s mandate, and she expressed some optimism that the institution was “agile” enough to change and adapt. Her own concern over Facebook’s “inaction” on hate speech and incitement was a major factor in her decision to join the board, she said. “The unwillingness to deal with these problems is leading increasingly to governments around the world, particularly in Africa, saying that to curb incitement to violence, they need to cut off the internet entirely,” she said. “For me it was important to be part of an institution that would be able not only to say whether or not Facebook’s decisions are in line with their community standards and international law, but also whether Facebook’s inaction is, because we will be able to look at content takedown but also content left up.” Asked whether she agreed with Facebook’s decision to leave the Trump “looting-shooting” post up, Owono demurred, noting that the board at the time had been in its earliest stages. When Owono was asked for her personal opinion, a PR representative interjected to refer to a statement the board issued at the time, which noted that the board had significant work to do before it could begin considering cases. That work has included making sure all board members are fully versed in Facebook’s community standards and international human rights law and getting technical training on the case management tool that will allow board members to receive and consider the appeals, Owono said. The tool was built by Facebook engineers with considerable input from oversight board members, according to a person familiar with the matter. One detail requested by the board members was to format user-submitted appeal statements with line numbers, so they will look similar to legal filings. At launch, it will be available in 18 languages, though that number includes both US and UK English and two types of Spanish. Owono said she wanted to ensure that the board’s work and decisions reflected both the diversity of Facebook’s users and the “diversity of the impact and where those impacts are occurring”, noting that a large majority of Facebook’s users are outside of the US. “There will be many other elections at the end of 2020 in which the role of platforms will also be scrutinized and should be scrutinized as well,” Owono said, including a general election in Myanmar on 8 November. “If we receive requests related to these elections, we’ll also pay the same attention and make the decisions that are being asked from us thoroughly and in accordance with international law principles.”